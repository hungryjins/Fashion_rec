# -*- coding: utf-8 -*-
"""generate SPLADE_embeddings

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sXkwYpfipL9GYVzb0K_nPvCVYSr4ZF_a
"""

# Needed for the SPLADE package
!pip install omegaconf

from google.colab import drive
drive.flush_and_unmount()

colab = True
fastcampus_dir = '/content/drive/MyDrive/fastcampus'

if colab:
  import os
  import zipfile
  from google.colab import drive
  drive.mount('/content/drive')
  os.chdir(fastcampus_dir)
  print("Current Working Directory: ", os.getcwd())

import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
import json

from splade.splade.models.transformer_rep import Splade
from transformers import AutoTokenizer

sparse_model_id = 'naver/splade-cocondenser-ensembledistil'

# splade = 'naver/splade-v3'
sparse_model = Splade(sparse_model_id, agg='max')
sparse_model.to('cuda')  # move to GPU if possible
sparse_model.eval()

tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)

embeddings = {}

with open('img_embeddings.json', 'r') as file:
    for line in file:
        # Convert each line to a dictionary
        embedding_dict = json.loads(line.strip())

        # Convert the list back to a NumPy array if necessary
        for img_name, emb_list in embedding_dict.items():
            embeddings[img_name] = np.array(emb_list)

image_embedddings = pd.DataFrame([embeddings]).T.reset_index()
image_embedddings.rename(columns={"index":"img_id", 0:"img_emb"}, inplace=True)

new_df = pd.read_csv("clothes_final_sparse_doc.csv")

base_path = "imaterialist-fashion-2020-fgvc7/cropped_images/"

new_df['img_path'] = base_path + new_df['ImageId'].astype(str) + "_" + new_df['entity_id'].astype(str) + ".jpg"
# Create a key for joining with the image df
new_df['img_id'] = new_df['ImageId'].astype(str) + "_" + new_df['entity_id'].astype(str)

new_df = pd.merge(new_df, image_embedddings, on='img_id', how='left')

import torch

def gen_sparse_vector(text):
    tokens = tokenizer(text, return_tensors="pt", padding=True, truncation=True)

    with torch.no_grad():
        sparse_emb = sparse_model(
            d_kwargs=tokens.to('cuda')
        )['d_rep'].squeeze()

    indices = sparse_emb.nonzero().squeeze().cpu().tolist()
    values = sparse_emb[indices].cpu().tolist()

    return indices, values

def upsert_format(id, text, img_emb):
    index, value = gen_sparse_vector(text)

    sparse_values = {
        "indices": index,
        "values": value
    }

    upsert = {
        "id": id,
        "values": img_emb,
        "sparse_values":sparse_values,
        "metadata":{"img_path":"imaterialist-fashion-2020-fgvc7/cropped_images/"+id+".jpg"}
    }
    return upsert

open('upsert_vectors.json', 'w').close()

upserts = list()

for _, row in tqdm(new_df.iterrows(), total=new_df.shape[0]):
    upserts.append(upsert_format(row['img_id'], row['doc'], row['img_emb'].tolist()))
    with open("upsert_vectors.json", 'a') as file:
      file.write(json.dumps(upsert_format(row['img_id'], row['doc'], row['img_emb'].tolist())) + '\n')

"""Check if it was created correctly"""

data_read = []

# Open the file in read mode
with open("upsert_vectors.json", 'r') as file:
    # Iterate through each line in the file
    for line in file:
        # Parse the JSON string into a Python dictionary
        data = json.loads(line)
        # Append the dictionary to the list
        data_read.append(data)

# Now, data_read contains all the dictionaries read from the file
print(f"Successfully read {len(data_read)} items from upsert_vectors.json")

# Optionally, print the dictionaries to verify

!pip install pinecone-client

## Upsert to pineconeDB!!
from pinecone import Pinecone

pc = Pinecone(api_key="YOUR_PINECONE_API_KEY")
index = pc.Index("fastcampus")
index.describe_index_stats()

index.upsert(upserts)