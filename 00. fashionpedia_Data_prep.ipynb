{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from ultralytics.utils.metrics import mask_iou\n",
        "import itertools\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# pandas dataframe display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno = pd.read_csv('imaterialist-fashion-2020-fgvc7/train.csv')\n",
        "with open('imaterialist-fashion-2020-fgvc7/label_descriptions.json', 'r') as file:\n",
        "    labels = json.load(file)\n",
        "\n",
        "categories = pd.DataFrame(labels['categories'])\n",
        "attributes = pd.DataFrame(labels['attributes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes.tail(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes.supercategory.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes.name.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno = pd.merge(anno, categories[['id', 'name', 'supercategory']], left_on='ClassId', right_on=['id'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "### 0. Data Exploration\n",
        "### 1. Understanding Types and Characteristics of Clothing (category & attributes)\n",
        "- Understanding the scope of the dataset\n",
        "### 2. Defining Relationships between Main/Sub Categories\n",
        "- Preprocessing for more complete data\n",
        "### 3. Converting Data for Recommendation Service Use\n",
        "- Data transformation considering service connectivity\n",
        "### 4. Preprocessing for Image Cropping\n",
        "- Data normalization for efficient search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Understanding Types and Characteristics of Clothing (category & attributes)\n",
        "#### : Examine what attributes each class has"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id_to_name = pd.Series(attributes.name.values, index=attributes.id).to_dict()\n",
        "\n",
        "# function to convert IDs to names\n",
        "def ids_to_names(ids):\n",
        "    if pd.isna(ids):\n",
        "        return np.nan\n",
        "    names = [id_to_name.get(int(id_), 'Unknown') for id_ in ids.split(',')]\n",
        "    return ', '.join(names)\n",
        "\n",
        "# Apply the function to the AttributesIds column\n",
        "anno['AttributesNames'] = anno['AttributesIds'].apply(ids_to_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id_to_name[115]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno_tmp = anno.copy()\n",
        "\n",
        "# Convert attributes from string format to list format\n",
        "anno_tmp['AttributesIds'] = anno_tmp['AttributesIds'].str.split(',')\n",
        "anno_tmp['AttributesNames'] = anno_tmp['AttributesNames'].str.split(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extend attributes row-wise\n",
        "exploded_df = anno_tmp.explode('AttributesIds')\n",
        "# Select only unique pairs based on 'name', 'AttributesIds'\n",
        "unique_pairs = exploded_df[['name', 'AttributesIds']].drop_duplicates()\n",
        "unique_pairs.reset_index(drop=True, inplace=True)\n",
        "unique_pairs = unique_pairs.loc[unique_pairs['AttributesIds'].notna()]\n",
        "unique_pairs['AttributesIds'] = unique_pairs['AttributesIds'].astype(int)\n",
        "unique_pairs.rename(columns={\"name\":\"class_name\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exploded_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_pairs.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert each attribute ID to human readable text\n",
        "pairs = pd.merge(unique_pairs, attributes, left_on='AttributesIds', right_on='id', how='left')\n",
        "pairs.sort_values(by=['class_name', 'id'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs.to_csv(\"clothes_pairs.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for c in pairs.class_name.unique():\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Attributes are not clearly distinguished by class name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs.loc[pairs['class_name']=='pants', 'name'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs.loc[pairs['class_name']=='jacket', 'name'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- trucker (jacket)\n",
        "\n",
        "<img src=\"https://www.billyreid.com/cdn/shop/files/f23_203-482_moleskin-tupelo-trucker-jacket_olive_201_A_3000x.jpg\" width=\"300\" height=\"300\">\n",
        "\n",
        "- houndstooth (pattern)\n",
        "\n",
        "<img src=\"https://www.thecuttingclass.com/wp-content/uploads/2011/03/593bfb3e455e5_houndstooth.jpg\" width=\"500\" height=\"300\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Defining Relationships between Main/Sub Categories\n",
        "#### : Examine annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Run-Length Encoding (RLE) format\n",
        "    - e.g.) 6068157 7 6073371 20 6078584 34\n",
        "    - When 2D is converted to 1D, pixels from the 6068157th position are annotated for 7 pixels\n",
        "    - Choice for efficient data storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.loc[0, 'EncodedPixels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = anno.loc[anno['ImageId']=='2f18aaab685a98876504a0f32d4c1d8e']\n",
        "tmp.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- At this time, labels referring to parts of clothing such as `garment parts` or `closures` are displayed as part of the annotation of other labels such as `shirt, blouse`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_single_mask(image, annoations, class_ids):\n",
        "    masks = []\n",
        "    shape = image.shape\n",
        "\n",
        "    # Initialize numpy array with shape same as image size\n",
        "    height, width = shape[:2]\n",
        "    mask = np.zeros((height, width)).reshape(-1)\n",
        "\n",
        "    # Iterate over encoded pixels and create mask\n",
        "    for segment, (pixel_str, class_id) in enumerate(zip(annoations, class_ids)):\n",
        "        splitted_pixels = list(map(int, pixel_str.split()))\n",
        "        pixel_starts = splitted_pixels[::2]\n",
        "        run_lengths = splitted_pixels[1::2]\n",
        "        assert max(pixel_starts) < mask.shape[0]\n",
        "        for pixel_start, run_length in zip(pixel_starts, run_lengths):\n",
        "            pixel_start = int(pixel_start) - 1\n",
        "            run_length = int(run_length)\n",
        "            mask[pixel_start:pixel_start+run_length] = 255 - class_id * 4\n",
        "    masks.append(mask.reshape((height, width), order='F'))\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_image_with_mask(image_path, mask):\n",
        "    # Load the original image\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Plotting the original image\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # Plotting the mask on top of the image\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(mask, cmap='jet', alpha=0.5)  # Overlaying the mask with transparency\n",
        "    plt.title('Image with Mask')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = mpimg.imread('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg')\n",
        "masks = create_single_mask(image, tmp['EncodedPixels'], tmp['id'])\n",
        "\n",
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Converting Data for Recommendation Service Use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The unit of clothing recommendation service is complete clothing items such as jackets, pants\n",
        "\n",
        "- Pockets, sleeves, collars, etc. should be considered together with upper body categories such as shirts and blouses\n",
        "    - Annotations of sub-categories (pockets, sleeves, collars) are made to overlap with annotations of main categories\n",
        "- Also, even the same pocket, pants pockets and upper body pockets exist together in one image\n",
        "- Therefore, through pair generation of sub and main categories, we should be able to consider the characteristics of the complete clothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_separate_masks(annoations, class_ids, height, width):\n",
        "    masks = []\n",
        "\n",
        "    for segment, (pixel_str, class_id) in enumerate(zip(annoations, class_ids)):\n",
        "        mask = np.zeros((height, width)).reshape(-1)\n",
        "        splitted_pixels = list(map(int, pixel_str.split()))\n",
        "        pixel_starts = splitted_pixels[::2]\n",
        "        run_lengths = splitted_pixels[1::2]\n",
        "        assert max(pixel_starts) < mask.shape[0]\n",
        "        for pixel_start, run_length in zip(pixel_starts, run_lengths):\n",
        "            pixel_start = int(pixel_start) - 1\n",
        "            run_length = int(run_length)\n",
        "            mask[pixel_start:pixel_start+run_length] = 1\n",
        "        masks.append(mask.reshape((height, width), order='F'))\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "masks = create_separate_masks(tmp['EncodedPixels'], tmp['id'], tmp['Height'].values[0], tmp['Width'].values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "masks[2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Suit characteristics: \")\n",
        "print(tmp.loc[8, 'AttributesNames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Jacket pocket characteristics: \")\n",
        "print(tmp.loc[5, 'AttributesNames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Pants characteristics: \")\n",
        "print(tmp.loc[9, 'AttributesNames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Pants pocket characteristics: \")\n",
        "print(tmp.loc[10, 'AttributesNames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Belt characteristics: \")\n",
        "print(tmp.loc[11, 'AttributesNames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Belt buckle characteristics: \")\n",
        "print(tmp.loc[12, 'AttributesNames'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Annotation pairs\n",
        "1. Convert annotation to binary mask format\n",
        "2. Search for the existence of a pair of annotations that overlap more than 90% within one image\n",
        "3. Integrate based on the annotation with the larger range among the annotation pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_mask(mask):\n",
        "\n",
        "    flattened_mask = mask.flatten()\n",
        "    mask_tensor = np.reshape(flattened_mask, (1, -1))\n",
        "\n",
        "    mask_tensor = torch.tensor(mask_tensor, dtype=torch.float32)\n",
        "    return mask_tensor\n",
        "\n",
        "def check_overlap(mask1, mask2, threshold=0.9):\n",
        "    \"\"\"\n",
        "    Determine if the overlap between two masks covers more than `threshold` of the smaller mask.\n",
        "    \"\"\"\n",
        "    # Calculate IoU using the mask_iou function\n",
        "    iou = mask_iou(mask1, mask2).item()\n",
        "    if iou==0:\n",
        "        return False\n",
        "    \n",
        "    # Calculate the areas of the masks\n",
        "    area1 = mask1.sum().item()\n",
        "    area2 = mask2.sum().item()\n",
        "    \n",
        "    # Determine the smaller mask\n",
        "    smaller_area = min(area1, area2)\n",
        "    \n",
        "    # Calculate the intersection area based on IoU and union\n",
        "    intersection = iou * (area1 + area2) / (1 + iou)\n",
        "    \n",
        "    # Check if the intersection covers more than threshold of the smaller mask\n",
        "    if intersection / smaller_area > threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = mpimg.imread('imaterialist-fashion-2020-fgvc7/train/{}.jpg'.format(tmp.ImageId.unique()[0]))\n",
        "masks = create_separate_masks(tmp['EncodedPixels'], tmp['id'], tmp['Height'].values[0], tmp['Width'].values[0])\n",
        "\n",
        "combinations = list(itertools.combinations(range(len(masks)), 2))\n",
        "\n",
        "pairs = list()\n",
        "\n",
        "# 모든 combination 고려\n",
        "for comb in combinations:\n",
        "    mask1 = masks[comb[0]]\n",
        "    mask2 = masks[comb[1]]\n",
        "    # 비교를 위해 flatten\n",
        "    flat1 = flatten_mask(mask1)\n",
        "    flat2 = flatten_mask(mask2)\n",
        "    # 두 binary mask들 중 작은 mask가 큰 mask와 90% 이상 픽셀을 공유하는지 여부 체크\n",
        "    if check_overlap(flat1, flat2):\n",
        "        # 둘 중 큰 mask를 선별하여 대표 mask로 설정\n",
        "        if mask1.sum() > mask2.sum():\n",
        "            pairs.append([comb[0], comb])\n",
        "        else:\n",
        "            pairs.append([comb[1], comb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Shirt\")\n",
        "tmp.loc[[0,1,2,3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Jacket')\n",
        "tmp.loc[[4,5,6,7,8,16]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Pants')\n",
        "tmp.loc[[9, 10]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Add characteristics of `sub-items` such as sleeves and pockets to one column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes.tail(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp['second_AttributesIds'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "main_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "main_pairs = list(set([i[0] for i in pairs]))\n",
        "\n",
        "for mp in main_pairs:\n",
        "    pairb = [i[1] for i in pairs if i[0]==mp]\n",
        "    print(\"Clothing related to clothing number {}: \".format(mp), pair)\n",
        "    flat_pair = list(set([element for tuple_ in pair for element in tuple_]))\n",
        "    sub_category = [i for i in flat_pair if i!=mp]\n",
        "    print(\"Sub-category of clothing number {}: \".format(mp), sub_category)\n",
        "    sub_attributes = tmp.loc[sub_category, 'AttributesIds'].values\n",
        "    sub_attributes = list(set(','.join(sub_attributes).split(',')))\n",
        "    sub_attributes = ','.join(sub_attributes)\n",
        "    print(\"Sub-characteristic id of clothing number {}: \".format(mp), sub_attributes)\n",
        "    tmp.loc[mp, 'second_AttributesIds'] = sub_attributes\n",
        "\n",
        "    print(\"-\"*20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flat_pair, sub_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(combinations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply to the entire dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Refer to `00.preprocess_annotations.py`\n",
        "- Execution method: `python 00.preprocess_annotations.py` (takes approximately 10 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_attribute_pairs(tmp_df, image_base_path='imaterialist-fashion-2020-fgvc7/train'):\n",
        "    tmp = tmp_df.reset_index(drop=True).copy()\n",
        "    image = mpimg.imread(os.path.join(image_base_path, tmp.ImageId.unique()[0]+'.jpg'))\n",
        "    # Create binary masks\n",
        "    masks = create_separate_masks(tmp['EncodedPixels'], tmp['id'], tmp['Height'].values[0], tmp['Width'].values[0])\n",
        "\n",
        "    combinations = list(itertools.combinations(range(len(masks)), 2))\n",
        "\n",
        "    pairs = list()\n",
        "\n",
        "    # Consider all combinations\n",
        "    for comb in combinations:\n",
        "        # Select binary masks\n",
        "        mask1 = masks[comb[0]]\n",
        "        mask2 = masks[comb[1]]\n",
        "        # Flatten for comparison\n",
        "        flat1 = flatten_mask(mask1)\n",
        "        flat2 = flatten_mask(mask2)\n",
        "        # Check if the smaller mask shares more than 90% of pixels with the larger mask\n",
        "        if check_overlap(flat1, flat2):\n",
        "            # Select the larger mask as the representative mask\n",
        "            if mask1.sum() > mask2.sum():\n",
        "                pairs.append([comb[0], comb])\n",
        "            else:\n",
        "                pairs.append([comb[1], comb])\n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_attribute_pairs(tmp_df, pairs):\n",
        "    tmp = tmp_df.reset_index(drop=True).copy()\n",
        "    # Convert to string value since some cases may not have attributes\n",
        "    tmp.loc[tmp['AttributesIds'].isna(), 'AttributesIds'] = ''\n",
        "    main_pairs = list(set([i[0] for i in pairs]))\n",
        "\n",
        "    for mp in main_pairs:\n",
        "        # Select pairs containing the main category\n",
        "        pair = [i[1] for i in pairs if i[0]==mp]\n",
        "        # Select only other IDs excluding the main category == sub-categories\n",
        "        flat_pair = list(set([element for tuple_ in pair for element in tuple_]))\n",
        "        sub_category = [i for i in flat_pair if i!=mp]\n",
        "        # Merge attributes of sub-categories into one\n",
        "        sub_attributes = tmp.loc[sub_category, 'AttributesIds'].values\n",
        "        sub_attributes = list(set(','.join(sub_attributes).split(',')))\n",
        "        sub_attributes = ','.join(sub_attributes)\n",
        "        # Save as second attribute of the main category\n",
        "        tmp.loc[mp, 'second_AttributesIds'] = sub_attributes\n",
        "\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 전체 데이터를 새로 만들 예정\n",
        "# new_anno = pd.DataFrame()\n",
        "\n",
        "# # 각 이미지 단위로 iterate\n",
        "# for image in tqdm(anno['ImageId'].unique()):\n",
        "#     # 한 이미지 단위 df\n",
        "#     tmp_df = anno.loc[anno['ImageId']==image]\n",
        "#     # pair 찾기\n",
        "#     pairs = search_attribute_pairs(tmp_df)\n",
        "#     if len(pairs)>0:\n",
        "#         # attribute들을 합쳐서 update\n",
        "#         tmp_df = merge_attribute_pairs(tmp_df, pairs)\n",
        "#     # 새로운 df에 추가\n",
        "#     new_anno = pd.concat([new_anno, tmp_df])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'outputs.json'\n",
        "\n",
        "data = []\n",
        "\n",
        "# Open the file for reading\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Parse the JSON data from each line\n",
        "        json_line = json.loads(line)\n",
        "        \n",
        "        # Optional: append the parsed JSON data to a list for further processing\n",
        "        data.append(json_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [pd.DataFrame(data[i]) for i in range(len(data))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno = pd.concat(data, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocessing for Image Cropping\n",
        "#### : Generate bounding boxes and crop images for individual storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 이때, 소매나 주머니 같은 하위 카테고리는 제거 (이미 관련 attribute을 상위카테고리의 second-attribute에 저장)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno = anno.loc[anno['ClassId']<27]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. mask\n",
        "2. bbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 왜 bbox?\n",
        "    - 주변 context까지 참고 할 수 있도록 이미지 crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = anno.loc[anno['ImageId']=='2f18aaab685a98876504a0f32d4c1d8e']\n",
        "\n",
        "masks = create_separate_masks(tmp['EncodedPixels'], tmp['ClassId'], tmp['Height'].values[0], tmp['Width'].values[0])\n",
        "\n",
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/2f18aaab685a98876504a0f32d4c1d8e.jpg', masks[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_bounding_box(mask):\n",
        "    \"\"\"\n",
        "    Find the bounding box of non-zero pixels in a mask.\n",
        "    \n",
        "    :param mask: The binary mask.\n",
        "    :return: A tuple (x_min, y_min, x_max, y_max) representing the bounding box.\n",
        "    \"\"\"\n",
        "    rows = np.any(mask, axis=1)\n",
        "    cols = np.any(mask, axis=0)\n",
        "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
        "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
        "    \n",
        "    return x_min, y_min, x_max, y_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 약 30분 소요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bboxes = list()\n",
        "\n",
        "for i in tqdm(anno.ImageId.unique()):\n",
        "    tmp = anno.loc[anno['ImageId']==i]\n",
        "    masks = create_separate_masks(tmp['EncodedPixels'], tmp['ClassId'], tmp['Height'].values[0], tmp['Width'].values[0])\n",
        "    bbox = [find_bounding_box(i) for i in masks]\n",
        "    bboxes.extend(bbox)\n",
        "    break\n",
        "\n",
        "anno.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 위 function이 오래 걸리기 때문에,\n",
        "# 시간 관계상 미리 만들어 놓은 data frame 활용\n",
        "\n",
        "def listify(string, encap_type=\"()\"):\n",
        "    return [int(num) for num in string.strip(encap_type).split(', ')]\n",
        "\n",
        "anno = pd.read_csv(\"clothes_final.csv\")\n",
        "\n",
        "# 처음 읽을 때, pandas dataframe에서 list가 아닌 string 값으로 인식하기 때문에 변환 필요\n",
        "anno['bbox'] = [listify(i) for i in anno['bbox']]\n",
        "anno['bbox_big'] = [listify(i) for i in anno['bbox_big']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enlarge_bounding_box(bbox, img_shape, scale=0.05):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    \n",
        "    # Calculate enlargement\n",
        "    enlarge_width = width * scale\n",
        "    enlarge_height = height * scale\n",
        "    \n",
        "    # Apply enlargement\n",
        "    x_min = max(0, x_min - enlarge_width // 2)\n",
        "    y_min = max(0, y_min - enlarge_height // 2)\n",
        "    x_max = min(img_shape[1], x_max + enlarge_width // 2)\n",
        "    y_max = min(img_shape[0], y_max + enlarge_height // 2)\n",
        "    \n",
        "    return int(x_min), int(y_min), int(x_max), int(y_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigger_bboxes = [enlarge_bounding_box(box, [h, w]) for box, h, w in zip(anno['bbox'], anno['Height'], anno['Width'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno['bbox_big'] = bigger_bboxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bbox가 알맞게 만들어졌는지 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_bounding_box(image, bbox, color=(0, 255, 0), thickness=20):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Draw the rectangle on the image\n",
        "    cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color[::-1], thickness)  # Convert color to RGB\n",
        "    \n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Hide the axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = anno.loc[anno['ImageId']==\"00000663ed1ff0c4e0132b9b9ac53f6e\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "masks = create_separate_masks(tmp['EncodedPixels'], tmp['ClassId'], tmp['Height'].values[0], tmp['Width'].values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/00000663ed1ff0c4e0132b9b9ac53f6e.jpg', masks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "draw = draw_bounding_box(cv2.imread(\"imaterialist-fashion-2020-fgvc7/train/00000663ed1ff0c4e0132b9b9ac53f6e.jpg\"), tmp['bbox'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "draw = draw_bounding_box(cv2.imread(\"imaterialist-fashion-2020-fgvc7/train/00000663ed1ff0c4e0132b9b9ac53f6e.jpg\"), tmp['bbox_big'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_image_with_mask('imaterialist-fashion-2020-fgvc7/train/00000663ed1ff0c4e0132b9b9ac53f6e.jpg', masks[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "draw = draw_bounding_box(cv2.imread(\"imaterialist-fashion-2020-fgvc7/train/00000663ed1ff0c4e0132b9b9ac53f6e.jpg\"), tmp['bbox_big'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_bbox_metrics(bbox):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    area = width * height\n",
        "    \n",
        "    return {'width': width, 'height': height, 'area': area}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- bounding box 관련 정보 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox_metrics = [calculate_bbox_metrics(i) for i in anno['bbox_big']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno = pd.concat([anno, pd.DataFrame(bbox_metrics)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- attribute과 classId 이름 다시 붙이기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# category\n",
        "anno = pd.merge(anno, categories[['id', 'name', 'supercategory']], left_on='ClassId', right_on=['id'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# attributionId 전처리\n",
        "def clean_attributes(attr_str):\n",
        "    if isinstance(attr_str, float):\n",
        "        return np.nan\n",
        "    l = attr_str.split(',')\n",
        "    l = [i for i in l if i != '']\n",
        "    s = ','.join(l)\n",
        "    if s=='':\n",
        "        return np.nan\n",
        "    else:\n",
        "        return s\n",
        "    \n",
        "\n",
        "anno.loc[anno['AttributesIds']=='', 'AttributesIds'] = np.nan\n",
        "\n",
        "anno['second_AttributesIds'] = anno['second_AttributesIds'].fillna(np.nan)\n",
        "anno.loc[anno['second_AttributesIds']=='', 'second_AttributesIds'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno['AttributesNames'] = [ids_to_names(i) for i in anno['AttributesIds']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno['second_AttributesIds'] = [clean_attributes(i) for i in anno['second_AttributesIds']]\n",
        "anno['second_AttributesNames'] = [ids_to_names(i) for i in anno['second_AttributesIds']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anno.to_csv(\"clothes_final.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 목차\n",
        "\n",
        "### 0. 데이터 탐색\n",
        "### 1. 옷의 종류와 특징 파악 (category & attributes)\n",
        "- 데이터 셋의 범위 파악\n",
        "### 2. 상위 / 하위 카테고리의 관계 정의\n",
        "- 보다 온전한 데이터를 위한 전처리 작업\n",
        "### 3. 추천 서비스에 활용할 단위의 데이터로 변환\n",
        "- 서비스와의 연계성을 고려한 데이터 변환\n",
        "### 4. 이미지 cropping을 위한 전처리\n",
        "- 효율적인 search를 위한 데이터 정규화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fashion",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
